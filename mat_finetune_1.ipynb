{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e0dfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracemalloc import start\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, ConcatDataset, TensorDataset\n",
    "from datasets.dataset import *\n",
    "# from models.Autoformer import *(我h'h'h)\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "import scipy.stats\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from utils.tools import EarlyStopping, adjust_learning_rate, visual\n",
    "from utils.metrics import metric\n",
    "import os\n",
    "\n",
    "from my_utils import *\n",
    "from networks.mat import Finetune\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from IPython import embed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea1782b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = '0'\n",
    "save_path = '/data/rech/dingqian/model_das/finetune_epoch_0'\n",
    "scratch = True\n",
    "ft_path = ['/data/rech/dingqian/data_das/finetune_epoch_0_train.npy', \n",
    "          '/data/rech/dingqian/data_das/finetune_epoch_0_test.npy']\n",
    "\n",
    "# check save_path is exist, if not, create it\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d7094ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['24564, 3881', '24564, 22813', '24564, 21957', '24564, 22813']\n",
      "18226\n"
     ]
    }
   ],
   "source": [
    "def check_mem(cuda_device):\n",
    "    devices_info = os.popen('\"/opt/bin/nvidia-smi\" --query-gpu=memory.total,memory.used --format=csv,nounits,noheader').read().strip().split(\"\\n\")\n",
    "    print(devices_info)\n",
    "    total, used = devices_info[int(cuda_device)].split(',')\n",
    "    return total,used\n",
    "\n",
    "def occumpy_mem(cuda_device):\n",
    "    total, used = check_mem(cuda_device)\n",
    "    total = int(total)\n",
    "    used = int(used)\n",
    "    max_mem = int(total * 0.9)\n",
    "    block_mem = max(0, max_mem - used)\n",
    "    print(block_mem)\n",
    "    x = torch.FloatTensor(256,1024,block_mem).to(f'cuda:{cuda_device}')\n",
    "    del x\n",
    "    \n",
    "occumpy_mem(cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fd286bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ft_path[0], 'rb') as f:\n",
    "    x_ft_train, style_ft_train, skip_ft_train = pickle.load(f)\n",
    "with open(ft_path[1], 'rb') as f:\n",
    "    x_ft_test, style_ft_test, skip_ft_test = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2374d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "picks_train = torch.load('/data/rech/dingqian/data_das/picks_train.pt')\n",
    "patches_train = torch.load('/data/rech/dingqian/data_das/patches_train.pt')\n",
    "\n",
    "picks_test = torch.load('/data/rech/dingqian/data_das/picks_test.pt')\n",
    "patches_test = torch.load('/data/rech/dingqian/data_das/patches_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc1037d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"finetune_new_train = [x_ft_train, style_ft_train]\\nfinetune_new_test = [x_ft_test, style_ft_test]\\nwith open('/data/rech/dingqian/data_das/finetune_new_train.npy', 'wb') as f:\\n    pickle.dump(finetune_new_train, f)\\n\\nwith open('/data/rech/dingqian/data_das/finetune_new_test.npy', 'wb') as f:\\n    pickle.dump(finetune_new_test, f)\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''finetune_new_train = [x_ft_train, style_ft_train]\n",
    "finetune_new_test = [x_ft_test, style_ft_test]\n",
    "with open('/data/rech/dingqian/data_das/finetune_new_train.npy', 'wb') as f:\n",
    "    pickle.dump(finetune_new_train, f)\n",
    "\n",
    "with open('/data/rech/dingqian/data_das/finetune_new_test.npy', 'wb') as f:\n",
    "    pickle.dump(finetune_new_test, f)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4241f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert picks to picks_filtered\n",
    "\n",
    "def picks_filtered(picks, patches):\n",
    "    picks_filtered = []\n",
    "    patches_filtered = []\n",
    "\n",
    "    for i, pick in enumerate(picks):\n",
    "        if pick.sum().item() > 0:\n",
    "            picks_filtered.append(pick)\n",
    "            patches_filtered.append(patches[i])\n",
    "    \n",
    "    return torch.stack(picks_filtered), torch.stack(patches_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e488e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "picks_train, patches_train = picks_filtered(picks_train, patches_train)\n",
    "picks_test, patches_test = picks_filtered(picks_test, patches_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5d850c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## picks_filtered to gaussian\n",
    "\n",
    "def gaussian_2d(x=0, y=0, mx=0, my=0, sx=1, sy=1):\n",
    "    # return 1 / (2*math.pi*sx*sy) * torch.exp(-((x - mx)**2 / (2*sx**2) + (y - my)**2 / (2*sy**2)))\n",
    "    return torch.exp(-((x - mx)**2 / (2*sx**2) + (y - my)**2 / (2*sy**2)))\n",
    "\n",
    "def tensor_to_hot(pick_oh_mat):\n",
    "    \n",
    "    pick_pos = torch.stack(torch.where(pick_oh_mat == 1), axis=1)\n",
    "    \n",
    "    h, w = 128, 128\n",
    "    x = torch.linspace(0, h-1, h)\n",
    "    y = torch.linspace(0, w-1, w)\n",
    "    x, y = torch.meshgrid(x, y)\n",
    "\n",
    "    z = torch.zeros(h, w)\n",
    "    for x0, y0 in pick_pos:\n",
    "        # z = torch.max(z, gaussian_2d(x, y, mx=x0, my=y0, sx=h/10, sy=w/10))\n",
    "        z = (z + gaussian_2d(x, y, mx=x0, my=y0, sx=h/100, sy=w/200)).clip(max=1.)\n",
    "    \n",
    "    return z\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d889b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get labels\n",
    "\n",
    "def get_labels(picks_filtered):\n",
    "    labels = []\n",
    "    for i, pick in enumerate(tqdm(picks_filtered)):\n",
    "        pick_oh = F.one_hot(pick.long(), 3)\n",
    "        pick_p = tensor_to_hot(pick_oh[:, :, 1])\n",
    "        pick_s = tensor_to_hot(pick_oh[:, :, 2])\n",
    "        \n",
    "        pick_n = (1 - pick_p - pick_s).clip(min=0.)\n",
    "        \n",
    "        pick_new = torch.stack([pick_n, pick_p, pick_s])\n",
    "        labels.append(pick_new)\n",
    "    \n",
    "    return torch.stack(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06a9fca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''pick_oh = F.one_hot(picks_train[0].long(), 3)\n",
    "%matplotlib inline\n",
    "plt.imshow(tensor_to_hot(pick_oh[:, :, 1]), aspect='auto', vmin=-0, vmax=1.0, cmap=\"seismic\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "451c9d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                   | 0/2054 [00:00<?, ?it/s]/Tmp/dingqian/miniconda3/envs/ptpy3/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2054/2054 [00:26<00:00, 76.91it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2124/2124 [00:26<00:00, 80.18it/s]\n"
     ]
    }
   ],
   "source": [
    "labels_train = get_labels(picks_train)\n",
    "labels_test = get_labels(picks_test)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eca0287d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlabels_train\u001b[49m\u001b[38;5;241m.\u001b[39mshape, labels_test\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels_train' is not defined"
     ]
    }
   ],
   "source": [
    "labels_train.shape, labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a8444951",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write a train function for each epoch\n",
    "\n",
    "def train_loop(train_loader, model, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i, (x, style, skip, labels, picks) in enumerate(tqdm(train_loader)):\n",
    "        x, style, skip, labels, picks = x.to(device), style.to(device), skip.to(device), labels.to(device), picks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        _, y = model(x, style, skip)\n",
    "        y = y.softmax(dim=1)\n",
    "        \n",
    "        label_indices = torch.where(picks.sum(-1) > 0)\n",
    "        labels = labels[label_indices[0], :, label_indices[1], :]\n",
    "        y = y[label_indices[0], :, label_indices[1], :]\n",
    "\n",
    "        loss = criterion(y, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    return train_loss / len(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c054f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(test_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (x, style, skip, labels, picks) in enumerate(test_loader):\n",
    "            x, style, skip, labels, picks = x.to(device), style.to(device), skip.to(device), labels.to(device), picks.to(device)\n",
    "            _, y = model(x, style, skip)\n",
    "            y = y.softmax(dim=1)\n",
    "            \n",
    "            label_indices = torch.where(picks.sum(-1) > 0)\n",
    "            labels = labels[label_indices[0], :, label_indices[1], :]\n",
    "            y = y[label_indices[0], :, label_indices[1], :]\n",
    "            \n",
    "            loss = criterion(y, labels)\n",
    "            test_loss += loss.item()\n",
    "    \n",
    "    return test_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d42bde8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output a sample image with predicted labels and ground truth labels on training set\n",
    "\n",
    "# get the first batch of data in train_loader\n",
    "\n",
    "def plot_sample(model, data_loader, epoch, prefix, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, style, skip, labels, picks = next(iter(data_loader))\n",
    "        x, style, skip, labels, picks = x.to(device), style.to(device), skip.to(device), labels.to(device), picks.to(device)\n",
    "        _, y = model(x, style, skip)\n",
    "        y = y.softmax(dim=1)\n",
    "\n",
    "        y = y.cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        x = x.cpu().numpy()\n",
    "\n",
    "        fig, ax = plt.subplots(2, 2, figsize=(15, 5))\n",
    "        ax[0][0].imshow(y[0][1], aspect='auto', vmin=-0, vmax=1.0, cmap=\"seismic\")\n",
    "        ax[0][1].imshow(labels[0][1], aspect='auto', vmin=-.0, vmax=1.0, cmap=\"seismic\")\n",
    "\n",
    "        ax[1][0].imshow(y[0][2], aspect='auto', vmin=-0, vmax=1.0, cmap=\"seismic\")\n",
    "        ax[1][1].imshow(labels[0][2], aspect='auto', vmin=-.0, vmax=1.0, cmap=\"seismic\")\n",
    "\n",
    "        # save fig to file\n",
    "        fig.savefig(f'{save_path}/{prefix}_{epoch}.png', dpi=300)\n",
    "\n",
    "        # clear fig ax\n",
    "        plt.close(fig)\n",
    "\n",
    "        print('Max y[1]: ', y[0][1].max(), 'Max y[2]: ', y[0][2].max())\n",
    "        print('Max labels[1]: ', labels[0][1].max(), 'Max labels[2]: ', labels[0][2].max())\n",
    "\n",
    "        ### x has 180 samples. using matplotlib to plot x in a grid of size 12x15\n",
    "\n",
    "        fig, ax = plt.subplots(12, 15, figsize=(15, 12))\n",
    "        for i in range(12):\n",
    "            for j in range(15):\n",
    "                ax[i][j].imshow(x[0][i*15+j], aspect='auto', vmin=-1.0, vmax=1.0, cmap=\"viridis\")\n",
    "                ax[i][j].axis('off')\n",
    "                \n",
    "        # save fig to file\n",
    "        fig.savefig(f'{save_path}/{prefix}_x_{epoch}.png', dpi=300)\n",
    "\n",
    "        # clear fig ax\n",
    "        plt.close(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "724cb57f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got Tensor)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/tmp/ipykernel_109690/40992448.py:3\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert numpy data to pytorch dataset\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m x_ft_train \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_ft_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m      4\u001b[0m style_ft_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(style_ft_train)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m      5\u001b[0m skip_ft_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(skip_ft_train)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got Tensor)"
     ]
    }
   ],
   "source": [
    "# Convert numpy data to pytorch dataset\n",
    "\n",
    "x_ft_train = torch.from_numpy(x_ft_train).float()\n",
    "style_ft_train = torch.from_numpy(style_ft_train).float()\n",
    "skip_ft_train = torch.from_numpy(skip_ft_train).float()\n",
    "\n",
    "x_ft_test = torch.from_numpy(x_ft_test).float()\n",
    "style_ft_test = torch.from_numpy(style_ft_test).float()\n",
    "skip_ft_test = torch.from_numpy(skip_ft_test).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81fe72c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset for training and testing\n",
    "# input data: x_ft, style_ft, skip_ft\n",
    "# output data: labels\n",
    "\n",
    "train_dataset = TensorDataset(x_ft_train, style_ft_train, skip_ft_train, labels_train, picks_train)\n",
    "test_dataset = TensorDataset(x_ft_test, style_ft_test, skip_ft_test, labels_test, picks_test)\n",
    "\n",
    "# Create dataloader for training and testing\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90417d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2124, 180, 64, 64]),\n",
       " torch.Size([2124, 540]),\n",
       " torch.Size([2124, 180, 128, 128]),\n",
       " torch.Size([2124, 3, 128, 128]),\n",
       " torch.Size([2124, 128, 128]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ft_test.shape, style_ft_test.shape, skip_ft_test.shape, labels_test.shape, picks_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3f392f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1250e-07, 1.0281e-06, 8.0667e-06, 5.4336e-05, 3.1423e-04, 1.5603e-03,\n",
       "        6.6534e-03, 2.4370e-02, 7.6714e-02, 2.0775e-01, 4.8496e-01, 9.7946e-01,\n",
       "        1.7239e+00, 2.6797e+00, 3.6559e+00, 4.2686e+00, 4.8575e+00, 5.1070e+00,\n",
       "        5.4112e+00, 5.6460e+00, 5.7238e+00, 5.7952e+00, 5.8434e+00, 5.8585e+00,\n",
       "        5.8353e+00, 5.7713e+00, 5.6681e+00, 5.5354e+00, 4.9895e+00, 4.3113e+00,\n",
       "        3.3278e+00, 1.8229e+00, 1.0301e+00, 9.0057e-01, 1.3705e+00, 2.4371e+00,\n",
       "        3.9248e+00, 4.9152e+00, 5.5618e+00, 6.2929e+00, 6.8179e+00, 7.2794e+00,\n",
       "        7.3275e+00, 7.2509e+00, 6.9057e+00, 6.2508e+00, 5.0894e+00, 3.3265e+00,\n",
       "        1.7310e+00, 7.9016e-01, 3.1660e-01, 1.1743e-01, 6.4144e-02, 1.1078e-01,\n",
       "        2.9073e-01, 7.0688e-01, 1.4994e+00, 2.7674e+00, 4.4335e+00, 5.3067e+00,\n",
       "        5.7442e+00, 5.8055e+00, 5.6663e+00, 5.4018e+00, 4.9775e+00, 4.6554e+00,\n",
       "        4.6154e+00, 4.8669e+00, 5.3493e+00, 5.8559e+00, 6.0805e+00, 6.2807e+00,\n",
       "        6.3170e+00, 6.2342e+00, 6.0858e+00, 5.8978e+00, 5.6904e+00, 5.4884e+00,\n",
       "        5.3244e+00, 5.2257e+00, 5.1264e+00, 5.0729e+00, 5.0488e+00, 5.0214e+00,\n",
       "        5.0161e+00, 5.0961e+00, 5.3157e+00, 5.5275e+00, 5.6178e+00, 5.7080e+00,\n",
       "        5.7796e+00, 5.8231e+00, 5.8431e+00, 5.8592e+00, 5.9001e+00, 5.9929e+00,\n",
       "        6.1508e+00, 6.3678e+00, 6.5156e+00, 6.5362e+00, 6.5112e+00, 6.4993e+00,\n",
       "        6.4894e+00, 6.4706e+00, 6.4435e+00, 6.4251e+00, 6.4418e+00, 6.5132e+00,\n",
       "        6.6379e+00, 6.7019e+00, 6.7383e+00, 6.7376e+00, 6.7002e+00, 6.6424e+00,\n",
       "        6.5281e+00, 6.4076e+00, 6.2975e+00, 6.1853e+00, 6.0685e+00, 5.9544e+00,\n",
       "        5.8498e+00, 5.7525e+00, 5.6543e+00, 5.5510e+00, 5.2607e+00, 4.8064e+00,\n",
       "        4.4315e+00, 4.1270e+00])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test[0][1].sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23f5d3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2124, 128, 128])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picks_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70457121",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test[0][:, :, torch.where(picks_test[0].sum(-1) > 0)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5acc2c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  0,  15,  16,  17,  19,  20,  21,  22,  23,  24,  25,  26,  27,  29,\n",
       "          38,  40,  41,  42,  43,  44,  45,  56,  59,  60,  61,  63,  68,  70,\n",
       "          71,  72,  73,  74,  76,  77,  78,  81,  82,  83,  84,  85,  87,  88,\n",
       "          89,  90,  91,  92,  93,  94,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "         104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
       "         120, 121, 122, 123, 127]),)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(picks_test[0].sum(1) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ba7f545a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['24564, 24243', '24564, 14433', '24564, 22813', '24564, 22113']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "import importlib\n",
    "import networks.mat as mat\n",
    "importlib.reload(mat)\n",
    "\n",
    "device = torch.device(f'cuda:{cuda_device}')\n",
    "\n",
    "model = mat.Finetune(img_channels=3).to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Define loss function as Softmax Cross Entropy\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define loss function as MSE loss\n",
    "\n",
    "# criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcaead0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train model and save best model on test set\n",
    "try:\n",
    "    model.load_state_dict(torch.load(f'{save_path}/last_model.pth'))\n",
    "    epoch_start = 4797\n",
    "except:\n",
    "    epoch_start = 0\n",
    " \n",
    "epochs = 4000\n",
    "best_loss = np.inf\n",
    "for epoch in range(epoch_start, epoch_start + epochs):\n",
    "    train_loss = train_loop(train_loader, model, optimizer, criterion, device)\n",
    "    test_loss = test_loop(test_loader, model, criterion, device)\n",
    "    print(f'Epoch {epoch}: train loss {train_loss:.4f}, test loss {test_loss:.4f}')\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        plot_sample(model, train_loader, epoch, 'train', device)\n",
    "        plot_sample(model, test_loader, epoch, 'test', device)\n",
    "    \n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        torch.save(model.state_dict(), f'{save_path}/best_model.pth')\n",
    "    \n",
    "    torch.save(model.state_dict(), f'{save_path}/last_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b8c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
