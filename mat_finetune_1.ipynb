{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e0dfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracemalloc import start\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, ConcatDataset, TensorDataset\n",
    "from datasets.dataset import *\n",
    "# from models.Autoformer import *(我h'h'h)\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "import scipy.stats\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from utils.tools import EarlyStopping, adjust_learning_rate, visual\n",
    "from utils.metrics import metric\n",
    "import os\n",
    "\n",
    "from my_utils import *\n",
    "from networks.mat import Finetune\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from IPython import embed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea1782b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = '0'\n",
    "save_path = '/data/rech/dingqian/model_das/finetune_epoch_0'\n",
    "scratch = True\n",
    "ft_path = ['/data/rech/dingqian/data_das/finetune_epoch_0_train.npy', \n",
    "          '/data/rech/dingqian/data_das/finetune_epoch_0_test.npy']\n",
    "\n",
    "# check save_path is exist, if not, create it\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d7094ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['24564, 3881', '24564, 22813', '24564, 21957', '24564, 22813']\n",
      "18226\n"
     ]
    }
   ],
   "source": [
    "def check_mem(cuda_device):\n",
    "    devices_info = os.popen('\"/opt/bin/nvidia-smi\" --query-gpu=memory.total,memory.used --format=csv,nounits,noheader').read().strip().split(\"\\n\")\n",
    "    print(devices_info)\n",
    "    total, used = devices_info[int(cuda_device)].split(',')\n",
    "    return total,used\n",
    "\n",
    "def occumpy_mem(cuda_device):\n",
    "    total, used = check_mem(cuda_device)\n",
    "    total = int(total)\n",
    "    used = int(used)\n",
    "    max_mem = int(total * 0.9)\n",
    "    block_mem = max(0, max_mem - used)\n",
    "    print(block_mem)\n",
    "    x = torch.FloatTensor(256,1024,block_mem).to(f'cuda:{cuda_device}')\n",
    "    del x\n",
    "    \n",
    "occumpy_mem(cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fd286bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ft_path[0], 'rb') as f:\n",
    "    x_ft_train, style_ft_train, skip_ft_train = pickle.load(f)\n",
    "with open(ft_path[1], 'rb') as f:\n",
    "    x_ft_test, style_ft_test, skip_ft_test = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2374d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "picks_train = torch.load('/data/rech/dingqian/data_das/picks_train.pt')\n",
    "patches_train = torch.load('/data/rech/dingqian/data_das/patches_train.pt')\n",
    "\n",
    "picks_test = torch.load('/data/rech/dingqian/data_das/picks_test.pt')\n",
    "patches_test = torch.load('/data/rech/dingqian/data_das/patches_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc1037d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"finetune_new_train = [x_ft_train, style_ft_train]\\nfinetune_new_test = [x_ft_test, style_ft_test]\\nwith open('/data/rech/dingqian/data_das/finetune_new_train.npy', 'wb') as f:\\n    pickle.dump(finetune_new_train, f)\\n\\nwith open('/data/rech/dingqian/data_das/finetune_new_test.npy', 'wb') as f:\\n    pickle.dump(finetune_new_test, f)\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''finetune_new_train = [x_ft_train, style_ft_train]\n",
    "finetune_new_test = [x_ft_test, style_ft_test]\n",
    "with open('/data/rech/dingqian/data_das/finetune_new_train.npy', 'wb') as f:\n",
    "    pickle.dump(finetune_new_train, f)\n",
    "\n",
    "with open('/data/rech/dingqian/data_das/finetune_new_test.npy', 'wb') as f:\n",
    "    pickle.dump(finetune_new_test, f)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4241f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert picks to picks_filtered\n",
    "\n",
    "def picks_filtered(picks, patches):\n",
    "    picks_filtered = []\n",
    "    patches_filtered = []\n",
    "\n",
    "    for i, pick in enumerate(picks):\n",
    "        if pick.sum().item() > 0:\n",
    "            picks_filtered.append(pick)\n",
    "            patches_filtered.append(patches[i])\n",
    "    \n",
    "    return torch.stack(picks_filtered), torch.stack(patches_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e488e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "picks_train, patches_train = picks_filtered(picks_train, patches_train)\n",
    "picks_test, patches_test = picks_filtered(picks_test, patches_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d850c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## picks_filtered to gaussian\n",
    "\n",
    "def gaussian_2d(x=0, y=0, mx=0, my=0, sx=1, sy=1):\n",
    "    # return 1 / (2*math.pi*sx*sy) * torch.exp(-((x - mx)**2 / (2*sx**2) + (y - my)**2 / (2*sy**2)))\n",
    "    return torch.exp(-((x - mx)**2 / (2*sx**2) + (y - my)**2 / (2*sy**2)))\n",
    "\n",
    "def tensor_to_hot(pick_oh_mat):\n",
    "    \n",
    "    pick_pos = torch.stack(torch.where(pick_oh_mat == 1), axis=1)\n",
    "    \n",
    "    h, w = 128, 128\n",
    "    x = torch.linspace(0, h-1, h)\n",
    "    y = torch.linspace(0, w-1, w)\n",
    "    x, y = torch.meshgrid(x, y)\n",
    "\n",
    "    z = torch.zeros(h, w)\n",
    "    for x0, y0 in pick_pos:\n",
    "        # z = torch.max(z, gaussian_2d(x, y, mx=x0, my=y0, sx=h/10, sy=w/10))\n",
    "        z = (z + gaussian_2d(x, y, mx=x0, my=y0, sx=h/100, sy=w/200)).clip(max=1.)\n",
    "    \n",
    "    return z\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d889b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get labels\n",
    "\n",
    "def get_labels(picks_filtered):\n",
    "    labels = []\n",
    "    for i, pick in enumerate(tqdm(picks_filtered)):\n",
    "        pick_oh = F.one_hot(pick.long(), 3)\n",
    "        pick_p = tensor_to_hot(pick_oh[:, :, 1])\n",
    "        pick_s = tensor_to_hot(pick_oh[:, :, 2])\n",
    "        \n",
    "        pick_n = (1 - pick_p - pick_s).clip(min=0.)\n",
    "        \n",
    "        pick_new = torch.stack([pick_n, pick_p, pick_s])\n",
    "        labels.append(pick_new)\n",
    "    \n",
    "    return torch.stack(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06a9fca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''pick_oh = F.one_hot(picks_train[0].long(), 3)\n",
    "%matplotlib inline\n",
    "plt.imshow(tensor_to_hot(pick_oh[:, :, 1]), aspect='auto', vmin=-0, vmax=1.0, cmap=\"seismic\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "451c9d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                   | 0/2054 [00:00<?, ?it/s]/Tmp/dingqian/miniconda3/envs/ptpy3/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2054/2054 [00:27<00:00, 75.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2124/2124 [00:26<00:00, 79.50it/s]\n"
     ]
    }
   ],
   "source": [
    "labels_train = get_labels(picks_train)\n",
    "labels_test = get_labels(picks_test)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eca0287d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2054, 3, 128, 128]), torch.Size([2124, 3, 128, 128]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape, labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8444951",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write a train function for each epoch\n",
    "\n",
    "def train_loop(train_loader, model, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i, (x, style, skip, labels, picks) in enumerate(tqdm(train_loader)):\n",
    "        x, style, skip, labels, picks = x.to(device), style.to(device), skip.to(device), labels.to(device), picks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        _, y = model(x, style, skip)\n",
    "        y = y.softmax(dim=1)\n",
    "        \n",
    "        label_indices = torch.where(picks.sum(-1) > 0)\n",
    "        labels = labels[label_indices[0], :, label_indices[1], :]\n",
    "        y = y[label_indices[0], :, label_indices[1], :]\n",
    "\n",
    "        loss = criterion(y, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    return train_loss / len(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c054f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(test_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (x, style, skip, labels, picks) in enumerate(test_loader):\n",
    "            x, style, skip, labels, picks = x.to(device), style.to(device), skip.to(device), labels.to(device), picks.to(device)\n",
    "            _, y = model(x, style, skip)\n",
    "            y = y.softmax(dim=1)\n",
    "            \n",
    "            label_indices = torch.where(picks.sum(-1) > 0)\n",
    "            labels = labels[label_indices[0], :, label_indices[1], :]\n",
    "            y = y[label_indices[0], :, label_indices[1], :]\n",
    "            \n",
    "            loss = criterion(y, labels)\n",
    "            test_loss += loss.item()\n",
    "    \n",
    "    return test_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d42bde8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output a sample image with predicted labels and ground truth labels on training set\n",
    "\n",
    "# get the first batch of data in train_loader\n",
    "\n",
    "def plot_sample(model, data_loader, epoch, prefix, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, style, skip, labels, picks = next(iter(data_loader))\n",
    "        x, style, skip, labels, picks = x.to(device), style.to(device), skip.to(device), labels.to(device), picks.to(device)\n",
    "        _, y = model(x, style, skip)\n",
    "        y = y.softmax(dim=1)\n",
    "\n",
    "        y = y.cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        x = x.cpu().numpy()\n",
    "\n",
    "        fig, ax = plt.subplots(2, 2, figsize=(15, 5))\n",
    "        ax[0][0].imshow(y[0][1], aspect='auto', vmin=-0, vmax=1.0, cmap=\"seismic\")\n",
    "        ax[0][1].imshow(labels[0][1], aspect='auto', vmin=-.0, vmax=1.0, cmap=\"seismic\")\n",
    "\n",
    "        ax[1][0].imshow(y[0][2], aspect='auto', vmin=-0, vmax=1.0, cmap=\"seismic\")\n",
    "        ax[1][1].imshow(labels[0][2], aspect='auto', vmin=-.0, vmax=1.0, cmap=\"seismic\")\n",
    "\n",
    "        # save fig to file\n",
    "        fig.savefig(f'{save_path}/{prefix}_{epoch}.png', dpi=300)\n",
    "\n",
    "        # clear fig ax\n",
    "        plt.close(fig)\n",
    "\n",
    "        print('Max y[1]: ', y[0][1].max(), 'Max y[2]: ', y[0][2].max())\n",
    "        print('Max labels[1]: ', labels[0][1].max(), 'Max labels[2]: ', labels[0][2].max())\n",
    "\n",
    "        ### x has 180 samples. using matplotlib to plot x in a grid of size 12x15\n",
    "\n",
    "        fig, ax = plt.subplots(12, 15, figsize=(15, 12))\n",
    "        for i in range(12):\n",
    "            for j in range(15):\n",
    "                ax[i][j].imshow(x[0][i*15+j], aspect='auto', vmin=-1.0, vmax=1.0, cmap=\"viridis\")\n",
    "                ax[i][j].axis('off')\n",
    "                \n",
    "        # save fig to file\n",
    "        fig.savefig(f'{save_path}/{prefix}_x_{epoch}.png', dpi=300)\n",
    "\n",
    "        # clear fig ax\n",
    "        plt.close(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "724cb57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy data to pytorch dataset\n",
    "\n",
    "x_ft_train = torch.from_numpy(x_ft_train).float()\n",
    "style_ft_train = torch.from_numpy(style_ft_train).float()\n",
    "skip_ft_train = torch.from_numpy(skip_ft_train).float()\n",
    "\n",
    "x_ft_test = torch.from_numpy(x_ft_test).float()\n",
    "style_ft_test = torch.from_numpy(style_ft_test).float()\n",
    "skip_ft_test = torch.from_numpy(skip_ft_test).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81fe72c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset for training and testing\n",
    "# input data: x_ft, style_ft, skip_ft\n",
    "# output data: labels\n",
    "\n",
    "train_dataset = TensorDataset(x_ft_train, style_ft_train, skip_ft_train, labels_train, picks_train)\n",
    "test_dataset = TensorDataset(x_ft_test, style_ft_test, skip_ft_test, labels_test, picks_test)\n",
    "\n",
    "# Create dataloader for training and testing\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90417d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2124, 180, 64, 64]),\n",
       " torch.Size([2124, 540]),\n",
       " torch.Size([2124, 180, 128, 128]),\n",
       " torch.Size([2124, 3, 128, 128]),\n",
       " torch.Size([2124, 128, 128]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ft_test.shape, style_ft_test.shape, skip_ft_test.shape, labels_test.shape, picks_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3f392f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.4261e-30, 1.6922e-26, 6.4110e-23, 1.3193e-19, 1.4746e-16, 8.9520e-14,\n",
       "        2.9519e-11, 5.2872e-09, 5.1436e-07, 2.7179e-05, 7.8007e-04, 1.2161e-02,\n",
       "        1.0297e-01, 4.7361e-01, 1.1839e+00, 1.6158e+00, 1.2990e+00, 1.0631e+00,\n",
       "        1.7524e+00, 2.2835e+00, 2.7202e+00, 2.8982e+00, 2.9370e+00, 2.9413e+00,\n",
       "        2.9370e+00, 2.8982e+00, 2.7196e+00, 2.2736e+00, 1.6683e+00, 5.8952e-01,\n",
       "        1.1594e-01, 1.2969e-02, 8.3495e-04, 8.0829e-04, 1.2189e-02, 1.0378e-01,\n",
       "        4.8655e-01, 1.2990e+00, 2.0812e+00, 2.5815e+00, 2.8365e+00, 3.3612e+00,\n",
       "        4.2418e+00, 3.8061e+00, 2.6378e+00, 1.7400e+00, 5.8952e-01, 1.1594e-01,\n",
       "        1.2968e-02, 8.0777e-04, 2.7699e-05, 5.1970e-07, 1.0633e-08, 5.1968e-07,\n",
       "        2.7694e-05, 8.0725e-04, 1.2941e-02, 1.1516e-01, 5.7733e-01, 1.6688e+00,\n",
       "        2.8852e+00, 2.9612e+00, 2.3635e+00, 1.8866e+00, 1.3104e+00, 5.9027e-01,\n",
       "        5.8955e-01, 1.2990e+00, 2.0027e+00, 2.4820e+00, 2.5777e+00, 2.9256e+00,\n",
       "        2.7213e+00, 2.6891e+00, 2.6673e+00, 2.6608e+00, 2.6528e+00, 2.5637e+00,\n",
       "        1.7847e+00, 1.1539e+00, 1.6737e+00, 2.0611e+00, 2.0904e+00, 1.8035e+00,\n",
       "        1.6683e+00, 1.6924e+00, 1.6732e+00, 1.8472e+00, 2.3124e+00, 2.7242e+00,\n",
       "        2.8982e+00, 2.9324e+00, 2.9028e+00, 2.7637e+00, 2.5015e+00, 2.3872e+00,\n",
       "        2.7494e+00, 2.9038e+00, 2.9759e+00, 3.0005e+00, 3.0587e+00, 3.2857e+00,\n",
       "        3.4295e+00, 3.5642e+00, 3.4958e+00, 2.9585e+00, 2.7463e+00, 2.7463e+00,\n",
       "        2.7991e+00, 3.2682e+00, 3.7473e+00, 3.6800e+00, 3.2857e+00, 3.0588e+00,\n",
       "        3.0027e+00, 2.9934e+00, 2.9754e+00, 2.9038e+00, 2.7667e+00, 2.5447e+00,\n",
       "        2.5362e+00, 2.7250e+00, 2.6814e+00, 2.2736e+00, 1.7069e+00, 1.0631e+00,\n",
       "        1.2990e+00, 1.6101e+00])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test[0][1].sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23f5d3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2124, 128, 128])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picks_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70457121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         ...,\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1769e-34,\n",
       "          1.1491e-43, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.6738e-35,\n",
       "          8.4078e-44, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.4722e-35,\n",
       "          3.3631e-44, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.7172e-10,\n",
       "          1.6453e-14, 3.3631e-44],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.1128e-10,\n",
       "          3.5773e-15, 7.0065e-45],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.4952e-11,\n",
       "          4.2248e-16, 1.4013e-45]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test[0][:, :, torch.where(picks_test[0].sum(-1) > 0)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5acc2c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  0,  15,  16,  17,  19,  20,  21,  22,  23,  24,  25,  26,  27,  29,\n",
       "          38,  40,  41,  42,  43,  44,  45,  56,  59,  60,  61,  63,  68,  70,\n",
       "          71,  72,  73,  74,  76,  77,  78,  81,  82,  83,  84,  85,  87,  88,\n",
       "          89,  90,  91,  92,  93,  94,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "         104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
       "         120, 121, 122, 123, 127]),)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(picks_test[0].sum(1) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba7f545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "import importlib\n",
    "import networks.mat as mat\n",
    "importlib.reload(mat)\n",
    "\n",
    "device = torch.device(f'cuda:{cuda_device}')\n",
    "\n",
    "model = mat.Finetune(img_channels=3).to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Define loss function as Softmax Cross Entropy\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define loss function as MSE loss\n",
    "\n",
    "# criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcaead0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train model and save best model on test set\n",
    "try:\n",
    "    model.load_state_dict(torch.load(f'{save_path}/last_model.pth'))\n",
    "    epoch_start = 4797\n",
    "except:\n",
    "    epoch_start = 0\n",
    " \n",
    "epochs = 4000\n",
    "best_loss = np.inf\n",
    "for epoch in range(epoch_start, epoch_start + epochs):\n",
    "    train_loss = train_loop(train_loader, model, optimizer, criterion, device)\n",
    "    test_loss = test_loop(test_loader, model, criterion, device)\n",
    "    print(f'Epoch {epoch}: train loss {train_loss:.4f}, test loss {test_loss:.4f}')\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        plot_sample(model, train_loader, epoch, 'train', device)\n",
    "        plot_sample(model, test_loader, epoch, 'test', device)\n",
    "    \n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        torch.save(model.state_dict(), f'{save_path}/best_model.pth')\n",
    "    \n",
    "    torch.save(model.state_dict(), f'{save_path}/last_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b8c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed() ############ For paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e081464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_paper(model, data, epoch, prefix, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, style, skip, labels, picks = data\n",
    "        x, style, skip, labels, picks = x.to(device), style.to(device), skip.to(device), labels.to(device), picks.to(device)\n",
    "        x = x.unsqueeze(0)\n",
    "        style = style.unsqueeze(0)\n",
    "        skip = skip.unsqueeze(0)\n",
    "        labels = labels.unsqueeze(0)\n",
    "        picks = picks.unsqueeze(0)\n",
    "        \n",
    "        _, y = model(x, style, skip)\n",
    "        y = y.softmax(dim=1)\n",
    "\n",
    "        y = y.cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        x = x.cpu().numpy()\n",
    "\n",
    "        fig, ax = plt.subplots(2, 2, figsize=(15, 5))\n",
    "        ax[0][0].imshow(y[0][1], aspect='auto', vmin=-0, vmax=1.0, cmap=\"seismic\")\n",
    "        ax[0][1].imshow(labels[0][1], aspect='auto', vmin=-.0, vmax=1.0, cmap=\"seismic\")\n",
    "\n",
    "        ax[1][0].imshow(y[0][2], aspect='auto', vmin=-0, vmax=1.0, cmap=\"seismic\")\n",
    "        ax[1][1].imshow(labels[0][2], aspect='auto', vmin=-.0, vmax=1.0, cmap=\"seismic\")\n",
    "\n",
    "        # save fig to file\n",
    "        fig.savefig(f'{save_path}/{prefix}_{epoch}.png', dpi=300)\n",
    "        print(f'{save_path}/{prefix}_{epoch}.png')\n",
    "\n",
    "        # clear fig ax\n",
    "        plt.close(fig)\n",
    "\n",
    "        print('Max y[1]: ', y[0][1].max(), 'Max y[2]: ', y[0][2].max())\n",
    "        print('Max labels[1]: ', labels[0][1].max(), 'Max labels[2]: ', labels[0][2].max())\n",
    "\n",
    "        ### x has 180 samples. using matplotlib to plot x in a grid of size 12x15\n",
    "\n",
    "        fig, ax = plt.subplots(12, 15, figsize=(15, 12))\n",
    "        for i in range(12):\n",
    "            for j in range(15):\n",
    "                ax[i][j].imshow(x[0][i*15+j], aspect='auto', vmin=-1.0, vmax=1.0, cmap=\"viridis\")\n",
    "                ax[i][j].axis('off')\n",
    "                \n",
    "        # save fig to file\n",
    "        fig.savefig(f'{save_path}/{prefix}_x_{epoch}.png', dpi=300)\n",
    "\n",
    "        # clear fig ax\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7f6933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afa38e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2054"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04fced6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2054"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patches_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b3a5d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_png(data, i):\n",
    "    # plot in square shape, without any axis\n",
    "\n",
    "    # plt.figure(figsize=(10, 8))\n",
    "    # plt.imshow(data.T, vmin=-2.0, vmax=2.0, cmap=\"seismic\", aspecgt='auto')\n",
    "    # plt.gca().invert_yaxis()\n",
    "    # plt.xlabel(\"Time\")\n",
    "    # plt.ylabel(\"Station\")\n",
    "\n",
    "    plt.figure(figsize=(8,8), frameon=False)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(data.T, aspect='auto', vmin=-2.0, vmax=2.0, cmap=\"seismic\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('{}.png'.format(i), bbox_inches='tight', pad_inches=0, dpi=100)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04d86420",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_png(patches_train[1].T, 'p0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "616bdc3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f'/data/rech/dingqian/model_das/finetune_epoch_0/best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ce1f41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/rech/dingqian/model_das/finetune_epoch_0/aaa_-1.png\n",
      "Max y[1]:  4.207309e-06 Max y[2]:  3.0936425e-07\n",
      "Max labels[1]:  1.0 Max labels[2]:  1.0\n"
     ]
    }
   ],
   "source": [
    "plot_sample_paper(model, train_dataset[0], -1, 'aaa', device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
